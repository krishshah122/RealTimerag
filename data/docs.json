{"0": {"text": "Order delays detected in kota due to a driver strike affecting last-mile delivery.", "metadata": {"city": "kota"}}, "1": {"text": "Inventory mismatch detected for electronics category where listed stock does not match warehouse count.", "metadata": {}}, "2": {"text": "Android app crashes reported on login screen after the latest version update.", "metadata": {}}, "3": {"text": "Android app crashes reported on login screen after the latest version update.", "metadata": {}}, "4": {"text": "Payment fails when clicking submit", "metadata": {"user": "HR", "priority": "high"}}, "5": {"text": "Payment fails when clicking submit", "metadata": {"user": "HR", "priority": "high"}}, "6": {"text": "Search service response time has increased significantly, causing slow product discovery for users.", "metadata": {"service": "search-service", "avg_latency_ms": 3200, "severity": "medium"}}, "7": {"text": "search service problem is solve dnow everything is fine done by devops team.", "metadata": {"service": "search-service", "avg_latency_ms": 3200, "severity": "medium"}}, "8": {"text": "Checkout page returns 500 error when user clicks 'Pay Now'. Payment gateway timeout.", "metadata": {"priority": "Blocker", "source": "Jira", "ticket_id": "PROD-2391", "team_tag": "devops"}},
 "9": {"text": "Deployment #8841 to production failed. Health check timed out after 300s.", "metadata": {"service": "api-gateway", "source": "Jenkins", "build_url": "jenkins/job/deploy/8841", "team_tag": "devops"}}, "10": {"text": "CRITICAL: Database primary node (db-01) CPU usage > 95% for 5 minutes.", "metadata": {"severity": "Critical", "source": "PagerDuty", "region": "us-east-1", "team_tag": "devops"}},
 "11": {"text": "Multiple failed login attempts detected from IP 192.168.1.55 (Brute Force Pattern).", "metadata": {"level": "Warning", "source": "Splunk", "user_agent": "Unknown", "team_tag": "devops"}}, "12": {"text": "\"The 2:00 PM production rollout for the 'Payment Gateway' service has stalled in the Mumbai region. Our Kubernetes cluster is throwing an ImagePullBackOff error across all worker nodes. It appears the automated CI/CD pipeline failed to refresh the authentication token for the private Docker registry. No new pods are spinning up, and the previous version is currently handling 100% of the traffic, which is causing a slight increase in CPU load.\"", "metadata": {"source": "Manual Entry", "severity": "high", "team_tag": "devops"}}, "13": {"text": "\"The 'Order-Processing' backend is currently rejecting approximately 12% of incoming checkout requests. Logs indicate the service has exhausted its connection pool to the primary PostgreSQL instance. This looks like a regression from last night\u2019s 'Zomato Gold' update where zombie connections aren't being closed properly after a transaction fails. We are manually killing idle sessions while the dev team prepares a hotfix.\"", "metadata": {"source": "Manual Entry", "severity": "medium", "team_tag": "devops"}}, "14": {"text": "\"High-priority alert: The log-ingestor-node-04 is at 96% disk capacity. A massive influx of debug logs from the new 'Partner App' revamp has overwhelmed the standard log-rotation cycle. If the partition hits 100%, we will lose all real-time telemetry for the delivery fleet. The DevOps team is currently re-routing the Kafka stream to the secondary buffer and initiating an immediate cleanup of archived logs older than 24 hours.\"", "metadata": {"source": "Manual Entry", "severity": "critical", "team_tag": "devops"}}}